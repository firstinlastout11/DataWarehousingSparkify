{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import configparser\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dwh.cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-02ea94bdcfb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dwh.cfg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mKEY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AWS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ACCESS_KEY'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mSECRET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AWS'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SECRET'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dwh.cfg'"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dwh.cfg'))\n",
    "\n",
    "KEY = config.get('AWS','ACCESS_KEY')\n",
    "SECRET = config.get('AWS','SECRET')\n",
    "\n",
    "DWH_CLUSTER_TYPE = config.get(\"DWH\",\"DWH_CLUSTER_TYPE\")\n",
    "DWH_NUM_NODES = config.get(\"DWH\",\"DWH_NUM_NODES\")\n",
    "DWH_NODE_TYPE = config.get(\"DWH\",\"DWH_NODE_TYPE\")\n",
    "\n",
    "DWH_CLUSTER_IDENTIFIER = config.get(\"DWH\",\"DWH_CLUSTER_IDENTIFIER\")\n",
    "DWH_DB = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_CLUSTER_DB = config.get(\"DWH\",\"DWH_DB\")\n",
    "DWH_DB_USER = config.get(\"DWH\",\"DWH_DB_USER\")\n",
    "DWH_DB_PASSWORD = config.get(\"DWH\",\"DWH_DB_PASSWORD\")\n",
    "DWH_PORT = config.get(\"DWH\",\"DWH_PORT\")\n",
    "DWH_IAM_ROLE_NAME = config.get(\"DWH\",'DWH_IAM_ROLE_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec2 = boto3.resource('ec2',\n",
    "                    region_name = 'us-west-2',\n",
    "                    aws_access_key_id = KEY,\n",
    "                    aws_secret_access_key = SECRET)\n",
    "\n",
    "s3 = boto3.resource('s3',\n",
    "                   region_name = 'us-west-2',\n",
    "                   aws_access_key_id = KEY,\n",
    "                   aws_secret_access_key = SECRET)\n",
    "iam = boto3.client('iam',\n",
    "                  region_name = 'us-west-2',\n",
    "                  aws_access_key_id = KEY,\n",
    "                  aws_secret_access_key = SECRET)\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name = 'us-west-2',\n",
    "                       aws_access_key_id = KEY,\n",
    "                       aws_secret_access_key = SECRET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the sample data sourcse on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NoOptionError",
     "evalue": "No option 'bucket' in section: 'S3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/configparser.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[1;32m    788\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m# support subclasses that define __missing__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bucket'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNoOptionError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-42390060aa2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLOG_DATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"S3\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"BUCKET\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDataBucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOG_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDataBucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPrefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'log_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/configparser.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_UNSET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNoOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoOptionError\u001b[0m: No option 'bucket' in section: 'S3'"
     ]
    }
   ],
   "source": [
    "LOG_DATA = config.get(\"S3\",\"BUCKET\")\n",
    "DataBucket = s3.Bucket(LOG_DATA)\n",
    "for obj in DataBucket.objects.filter(Prefix = 'log_data'):\n",
    "    print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObj = s3.get_object(Bucket='bucket_name', Key='key')\n",
    "for row in fileObj[\"body\"]:\n",
    "    line = row.decode('utf-8')\n",
    "    print(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "obj = s3.Object(LOG_DATA,'log_data/2018/11/2018-11-02-events.json')\n",
    "#data = json.load(obj.get()['Body'])\n",
    "#data\n",
    "json.load(obj.get()['Body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SONG_DATA = config.get(\"S3\",\"BUCKET\")\n",
    "DataBucket = s3.Bucket(SONG_DATA)\n",
    "for obj in DataBucket.objects.filter(Prefix='song_data'):\n",
    "    print(obj)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.Object(SONG_DATA, 'song_data/A/A/A/TRAAAAK128F9318786.json')\n",
    "data = json.load(obj.get()['Body'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP1: IAM ROLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 Creating a new IAM Role\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name dwhRole already exists.\n",
      "1.2 Attching Policy\n",
      "1.3 Get  the IAM Role ARN\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('1.1 Creating a new IAM Role')\n",
    "    dwhRole = iam.create_role(\n",
    "        Path = '/',\n",
    "        RoleName = DWH_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS servers on your behalf\",\n",
    "        AssumeRolePolicyDocument = json.dumps(\n",
    "            {'Statement': [{'Action':'sts:AssumeRole',\n",
    "                           'Effect':'Allow',\n",
    "                           'Principal':{'Service':'redshift.amazonaws.com'}}],\n",
    "            'Version': '2012-10-17'})\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print('1.2 Attching Policy')\n",
    "## Attaching Read-only Access\n",
    "iam.attach_role_policy(RoleName = DWH_IAM_ROLE_NAME,\n",
    "                      PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\",\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print('1.3 Get  the IAM Role ARN')\n",
    "roleArn = iam.get_role(RoleName = DWH_IAM_ROLE_NAME)['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred (ClusterAlreadyExists) when calling the CreateCluster operation: Cluster already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(\n",
    "        ClusterType = DWH_CLUSTER_TYPE,\n",
    "        NodeType = DWH_NODE_TYPE,\n",
    "        NumberOfNodes = int(DWH_NUM_NODES),\n",
    "        ClusterIdentifier = DWH_CLUSTER_IDENTIFIER,\n",
    "        DBName = DWH_DB,\n",
    "        MasterUsername = DWH_DB_USER,\n",
    "        MasterUserPassword = DWH_DB_PASSWORD,\n",
    "        IamRoles = [roleArn]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the cluster to see its status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>dwhcluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>dwhuser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>dwh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'dwhcluster.c77uvrb0sszx.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-c023bab8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                   Value  \n",
       "0  dwhcluster                                                                             \n",
       "1  dc2.large                                                                              \n",
       "2  available                                                                              \n",
       "3  dwhuser                                                                                \n",
       "4  dwh                                                                                    \n",
       "5  {'Address': 'dwhcluster.c77uvrb0sszx.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-c023bab8                                                                           \n",
       "7  4                                                                                      "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prettyRedShiftProps(props):\n",
    "        \n",
    "    pd.set_option('display.max_colwidth',-1)\n",
    "    keysToShow = [\"ClusterIdentifier\",\"NodeType\",\"ClusterStatus\",\"MasterUsername\",\"DBName\",\"Endpoint\",\"NumberOfNodes\",\"VpcId\"]\n",
    "    x = [(k,v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns = [\"Key\",\"Value\"])\n",
    "    \n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier = DWH_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedShiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DWH_ENDPOINT ::  dwhcluster.c77uvrb0sszx.us-west-2.redshift.amazonaws.com\n",
      "DWH_ROLE_ARN ::  arn:aws:iam::426439643124:role/dwhRole\n"
     ]
    }
   ],
   "source": [
    "DWH_ENDPOINT = myClusterProps['Endpoint']['Address']\n",
    "DWH_ROLE_ARN = myClusterProps['IamRoles'][0]['IamRoleArn']\n",
    "print(\"DWH_ENDPOINT :: \", DWH_ENDPOINT)\n",
    "print(\"DWH_ROLE_ARN :: \", DWH_ROLE_ARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open an incoming TCP port to access the cluster endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-95be3bce')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vpc = ec2.Vpc(id=myClusterProps['VpcId'])\n",
    "    defaultSg = list(vpc.security_groups.all())[0]\n",
    "    print(defaultSg)\n",
    "    \n",
    "    defaultSg.authorize_ingress(\n",
    "        GroupName = defaultSg.group_name,\n",
    "        CidrIp = '0.0.0.0/0',\n",
    "        IpProtocol = 'TCP',\n",
    "        FromPort = int(DWH_PORT),\n",
    "        ToPort = int(DWH_PORT)\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Connected: dwhuser@dwh'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn_string = \"postgresql://{}:{}@{}:{}/{}\".format(DWH_DB_USER, DWH_DB_PASSWORD, DWH_ENDPOINT, DWH_PORT, DWH_DB)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.c77uvrb0sszx.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "8056 rows affected.\n",
      "(psycopg2.ProgrammingError) syntax error at or near \"LIMIT\"\n",
      "LINE 1: LIMIT 5;\n",
      "        ^\n",
      "\n",
      "[SQL: LIMIT 5;]\n",
      "(Background on this error at: http://sqlalche.me/e/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT *\n",
    "FROM staging_events\n",
    "LIMIT 5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: create_tables.py: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://dwhuser:***@dwhcluster.c77uvrb0sszx.us-west-2.redshift.amazonaws.com:5439/dwh\n",
      "(psycopg2.ProgrammingError) relation \"songs\" does not exist\n",
      "\n",
      "[SQL: SELECT *\n",
      "FROM songs;]\n",
      "(Background on this error at: http://sqlalche.me/e/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql SELECT *\n",
    "FROM songs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101.json        Untitled.ipynb   dwh.cfg          sql_queries.py\r\n",
      "README (1).md    create_tables.py etl.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"create_tables.py\", line 32, in <module>\r\n",
      "    main()\r\n",
      "  File \"create_tables.py\", line 22, in main\r\n",
      "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\r\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py\", line 130, in connect\r\n",
      "    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\r\n",
      "psycopg2.OperationalError: could not translate host name \"dwhCluster\" to address: nodename nor servname provided, or not known\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python create_tables.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
